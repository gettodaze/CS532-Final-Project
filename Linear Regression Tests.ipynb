{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from numpy import linspace, dot\n",
    "import scipy.signal as signal\n",
    "from numpy.linalg import svd\n",
    "from collections import defaultdict\n",
    "from matplotlib.pyplot import plot\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score\n",
    "NEGATIVE_LABEL = \"control\"\n",
    "POSITIVE_LABEL = 'injured'\n",
    "\n",
    "def get_filepaths_and_meta(csv_folder):\n",
    "    ret = [extract_meta(f) for f in os.listdir(csv_folder) if f.endswith('.csv')]\n",
    "    for x in ret:\n",
    "        x['filepath'] = os.path.join(csv_folder, x['filepath'])\n",
    "    return ret\n",
    "\n",
    "def read_and_process_csv(csv_fpath):\n",
    "    df = pd.read_csv(csv_fpath)\n",
    "    del df[df.columns[-1]]\n",
    "    del df['Unnamed: 0']\n",
    "    return df\n",
    "\n",
    "def pca(df):\n",
    "    num_pixels = len(df)\n",
    "    df_standardized = (df - df.mean()) / df.std()\n",
    "    df_standardized = df_standardized.fillna(0)\n",
    "    covariance_mat = np.cov(df_standardized.values)\n",
    "    # img = (covariance_mat-covariance_mat.min()) *255 / (covariance_mat.max()-covariance_mat.min())\n",
    "    # plt.imshow(img)\n",
    "    # plt.show()\n",
    "    return svd(covariance_mat, full_matrices=False)\n",
    "\n",
    "def dim_reduction(df):\n",
    "    U, S, Vh = pca(df)\n",
    "    total_s = sum(S)\n",
    "    cumsum = 0\n",
    "    for i in range(len(S)):\n",
    "        cumsum += S[i]/total_s\n",
    "        if cumsum > .99:\n",
    "            break;\n",
    "    return dot(dot(U,S),Vh)\n",
    "\n",
    "def select_tissue_region(df_feature_set):\n",
    "    [U, S, V] = pca(df_feature_set)\n",
    "    S_DIAG = np.diag(S)\n",
    "    dim_red_data = dot(U[:, :2], S_DIAG[:2, :2])\n",
    "    kmeans = KMeans(n_clusters=3, n_init=15)\n",
    "    kmeans.fit(df_feature_set)\n",
    "    y_kmeans = kmeans.predict(df_feature_set)\n",
    "    df_clusters = df_feature_set\n",
    "    df_clusters['clusters'] = y_kmeans\n",
    "    unique, counts = np.unique(y_kmeans, return_counts=True)\n",
    "    cluster_counts = dict(zip(unique, counts))\n",
    "    white_space_key = max(cluster_counts, key=cluster_counts.get)\n",
    "    df_remove_white_space = df_clusters[df_clusters['clusters'] != white_space_key]\n",
    "\n",
    "    del df_remove_white_space['clusters']\n",
    "    return df_remove_white_space\n",
    "\n",
    "\n",
    "def kmeans(df, n_clusters):\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    kmeans.fit(df.values)\n",
    "    return kmeans\n",
    "\n",
    "def graph_ndim_kmeans(df, n_clusters):\n",
    "    U, S, Vh = pca(df)\n",
    "    xs = dot(S[0],Vh[0,:])\n",
    "    ys = dot(S[1],Vh[1,:])\n",
    "    labels, centers = kmeans(df, n_clusters)\n",
    "    plt.scatter(xs, ys, c=labels, s=20, cmap='viridis')\n",
    "    # plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5)\n",
    "    plt.title('K-means of Pixel MS data')\n",
    "    plt.xlabel('Singular Vector 1')\n",
    "    plt.ylabel('Singular Vector 2')\n",
    "    plt.show()\n",
    "\n",
    "def day_groups(files_and_meta):\n",
    "    ret = defaultdict(lambda: [])\n",
    "    for fam in files_and_meta:\n",
    "        ret[(fam['label'], fam['day'])].append((fam, read_and_process_csv(fam['filepath'])))\n",
    "    return ret\n",
    "\n",
    "def extract_meta(fpath):\n",
    "    regex_search = re.search(r'(.*)_Day(\\d\\d)_(\\d\\d)_(\\d\\d)x(\\d\\d)_', fpath)\n",
    "    label, day, experiment, size_y, size_x = regex_search.groups()\n",
    "    assert label.lower() in [NEGATIVE_LABEL, POSITIVE_LABEL]\n",
    "    return {\n",
    "        'filepath': fpath,\n",
    "        'label': 1 if label.lower() == POSITIVE_LABEL else -1,\n",
    "        'day': int(day),\n",
    "        'experiment': int(experiment),\n",
    "        'x': int(size_x),\n",
    "        'y': int(size_y)\n",
    "    }\n",
    "\n",
    "def filter_meta_day_exp(day, experiment):\n",
    "    experiments = get_filepaths_and_meta(input_folder);\n",
    "    ret = filter(lambda x: x['day'] == day and x['experiment'] == experiment,experiments)\n",
    "    return list(ret)\n",
    "\n",
    "def get_x_y(day, experiment):\n",
    "    meta = filter_meta_day_exp(day, experiment)\n",
    "    print(meta[0]['filepath'])\n",
    "    print(meta[1]['filepath'])\n",
    "    x0 = select_tissue_region(read_and_process_csv(meta[0]['filepath'])).values\n",
    "    y0 = np.ones(len(x0)) * meta[0]['label']\n",
    "    x1 = select_tissue_region(read_and_process_csv(meta[1]['filepath'])).values\n",
    "    y1 = np.ones(len(x1)) * meta[1]['label']\n",
    "    return np.vstack((x0,x1)), np.append(y0,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\wfs1\\users$\\mccloskey\\Downloads\\csvData-20190806T210426Z-001\\csvData\\aggregates (bin=1000)\\Control_Day07_02_30x30_aggregated.csv\n",
      "\\\\wfs1\\users$\\mccloskey\\Downloads\\csvData-20190806T210426Z-001\\csvData\\aggregates (bin=1000)\\Injured_Day07_02_31x30_aggregated.csv\n"
     ]
    }
   ],
   "source": [
    "input_folder = r\"\\\\wfs1\\users$\\mccloskey\\Downloads\\csvData-20190806T210426Z-001\\csvData\\aggregates (bin=1000)\"\n",
    "X, y = get_x_y()\n",
    "X_standardized = (X - X.mean()) / X.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_reduction(df):\n",
    "    U, S, Vh = pca(df)\n",
    "    total_s = sum(S)\n",
    "    cumsum = 0\n",
    "    for i in range(len(S)):\n",
    "        cumsum += S[i]/total_s\n",
    "        if cumsum > .99:\n",
    "            break;\n",
    "    return dot(dot(U,S),Vh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lasso = linear_model.LinearRegression()\n",
    "lasso.fit(X_standardized,y)\n",
    "score = cross_val_score(lasso, X_standardized, y, cv=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\wfs1\\users$\\mccloskey\\Downloads\\csvData-20190806T210426Z-001\\csvData\\aggregates (bin=1000)\\Control_Day07_01_29x29_aggregated.csv\n",
      "\\\\wfs1\\users$\\mccloskey\\Downloads\\csvData-20190806T210426Z-001\\csvData\\aggregates (bin=1000)\\Injured_Day07_01_38x35_aggregated.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3415492957746479"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2, y2 = get_x_y(7,1)\n",
    "X2_standardized = (X2 - X2.mean()) / X2.std()\n",
    "y2_pred = np.sign(lasso.predict(X2_standardized))\n",
    "f1_score(y2, y2_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\\\wfs1\\users$\\mccloskey\\Downloads\\csvData-20190806T210426Z-001\\csvData\\aggregates (bin=1000)\\Control_Day03_02_35x34_aggregated.csv\n",
      "\\\\wfs1\\users$\\mccloskey\\Downloads\\csvData-20190806T210426Z-001\\csvData\\aggregates (bin=1000)\\Injured_Day03_02_37x33_aggregated.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[502755.6875    ,      0.        ,  50773.81640625, ...,\n",
       "             0.        ,      0.        ,      0.        ],\n",
       "       [422178.84375   ,      0.        ,      0.        , ...,\n",
       "             0.        ,      0.        ,      0.        ],\n",
       "       [565333.3046875 ,      0.        ,  53997.140625  , ...,\n",
       "             0.        ,      0.        ,      0.        ],\n",
       "       ...,\n",
       "       [445135.703125  ,      0.        ,      0.        , ...,\n",
       "             0.        ,      0.        ,      0.        ],\n",
       "       [494587.578125  ,      0.        ,  52764.4921875 , ...,\n",
       "             0.        ,      0.        ,      0.        ],\n",
       "       [441153.609375  ,      0.        ,      0.        , ...,\n",
       "             0.        ,      0.        ,      0.        ]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2, y2 = get_x_y(3,2)\n",
    "X2_standardized = (X2 - X2.mean()) / X2.std()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(493, 249)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_standardized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.43915544, -0.46934391,  0.81051543, ..., -0.46934391,\n",
       "        -0.46934391, -0.46934391],\n",
       "       [ 2.15477345, -0.46934391,  0.63016466, ..., -0.46934391,\n",
       "        -0.46934391, -0.46934391],\n",
       "       [ 2.0010301 , -0.46934391,  0.57276638, ..., -0.46934391,\n",
       "        -0.46934391, -0.46934391],\n",
       "       ...,\n",
       "       [ 1.68272576, -0.46934391,  0.56165441, ..., -0.46934391,\n",
       "        -0.46934391, -0.46934391],\n",
       "       [ 0.93495153, -0.46934391,  0.21005842, ..., -0.46934391,\n",
       "        -0.46934391, -0.46934391],\n",
       "       [ 1.63850939, -0.46934391,  0.55334769, ..., -0.46934391,\n",
       "        -0.46934391, -0.46934391]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
